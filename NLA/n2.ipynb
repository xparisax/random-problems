{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the positive definite-symmetric matrix A(n*n) and vector b = [1,1,...,1] solve AX=b with the methods below for n= 5,10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2. -1.  0.  0.  0.  0.]\n",
      " [-1.  2. -1.  0.  0.  0.]\n",
      " [ 0. -1.  2. -1.  0.  0.]\n",
      " [ 0.  0. -1.  2. -1.  0.]\n",
      " [ 0.  0.  0. -1.  2. -1.]\n",
      " [ 0.  0.  0.  0. -1.  2.]]\n",
      "3.801937735804838\n"
     ]
    }
   ],
   "source": [
    "M = np.diag([-1]*(5),1)+np.eye(6)*2+np.diag([-1]*(5),-1)\n",
    "print(M)\n",
    "print(LA.norm(M,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the norm of this matrix is greater than 1 therefore given any vector X(0) it does not necessarily converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jacobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi(A):\n",
    "    b = np.ones_like(A[0])\n",
    "    x = np.zeros_like(b)\n",
    "    norm = 1\n",
    "    count = 0\n",
    "    \n",
    "    while norm > 5.0e-4:\n",
    "        count += 1\n",
    "        \n",
    "        for i in range(A.shape[0]):\n",
    "            L = np.dot(A[i, :i], x[:i])\n",
    "            U = np.dot(A[i, i+1:], x[i+1:])\n",
    "            x[i] = (b[i] - L - U) / A[i, i]\n",
    "                \n",
    "        r = np.dot(A, x) - b   \n",
    "        norm = LA.norm(r, np.inf)\n",
    "        if norm > 1.0e30:\n",
    "            print(\"Norm is not converging\")\n",
    "            break\n",
    "        \n",
    "    print(\"Solution: \" + \"\\n\" + \"{0}\".format(x) + \"\\n\" + \"iteration: \" + str(count))\n",
    "    print(\"||AX - b||: \" + str(norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: \n",
      "[2.49919748 3.99879622 4.49879622 3.99909717 2.49954858]\n",
      "iteration: 29\n",
      "||AX - b||: 0.000401258523591963\n",
      "----------------------------------------------------------------------\n",
      "Solution: \n",
      "[ 4.99806354  8.99643449 11.99521774 13.99447716 14.99423373 14.9944673\n",
      " 13.99512148 11.99611097  8.9973306   4.9986653 ]\n",
      "iteration: 96\n",
      "||AX - b||: 0.0004971480656337235\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in [5,10]:\n",
    "    A = np.diag([-1]*(i-1),1)+np.eye(i)*2+np.diag([-1]*(i-1),-1)\n",
    "    jacobi(A)\n",
    "    print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sor(A, omega=0.9):\n",
    "    b = np.ones_like(A[0])\n",
    "    x = np.zeros_like(b)\n",
    "    norm = 1\n",
    "    count = 0\n",
    "\n",
    "    while norm > 5.0e-4:\n",
    "        count += 1\n",
    "        x_new = np.zeros_like(x)\n",
    "        \n",
    "        for i in range(A.shape[0]):\n",
    "            L = np.dot(A[i, :i], x_new[:i])\n",
    "            U = np.dot(A[i, i+1:], x[i+1:])\n",
    "            x_new[i] = ((b[i] - L - U)*omega) / A[i, i] + (1-omega)*x[i]\n",
    "            \n",
    "        r = np.dot(A, x) - b   \n",
    "        norm = LA.norm(r, np.inf)\n",
    "        if norm > 1.0e30:\n",
    "            print(\"Norm is not converging\")\n",
    "            break\n",
    "        x = x_new\n",
    "        \n",
    "    print(\"Solution: \" + \"\\n\" + \"{0}\".format(x) + \"\\n\" + \"iteration: \" + str(count))\n",
    "    print(\"||AX - b||: \" + str(norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: \n",
      "[2.49920501 3.99877232 4.49873609 3.99902409 2.49949765]\n",
      "iteration: 36\n",
      "||AX - b||: 0.0004987377715721664\n",
      "----------------------------------------------------------------------\n",
      "Solution: \n",
      "[ 4.99824866  8.99675024 11.99560733 13.9948876  14.99462071 14.99479844\n",
      " 13.99537777 11.99628659  8.99743131  4.99870566]\n",
      "iteration: 119\n",
      "||AX - b||: 0.00048432157147004773\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in [5,10]:\n",
    "    A = np.diag([-1]*(i-1),1)+np.eye(i)*2+np.diag([-1]*(i-1),-1)\n",
    "    sor(A)\n",
    "    print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By increasing the omega achieving the final result takes less iterations. Also this shows that if omega equals 1 we need less iterations but that leads us to guass-seidel method (that in this case is similar to jacobi method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lambda method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lmethod(A, lmda=2):\n",
    "    b = np.ones_like(A[0])\n",
    "    x = np.zeros_like(b)\n",
    "    norm = 1\n",
    "    count = 0\n",
    "\n",
    "    while norm > 5.0e-4:\n",
    "        count += 1\n",
    "        Ax = np.dot(A,x)\n",
    "        x = x - ((Ax - b) / lmda)\n",
    "            \n",
    "        r = np.dot(A, x) - b   \n",
    "        norm = LA.norm(r, np.inf)\n",
    "        if norm > 1.0e30:\n",
    "            print(\"Norm is not converging\")\n",
    "            break\n",
    "        \n",
    "    print(\"Solution: \" + \"\\n\" + \"{0}\".format(x) + \"\\n\" + \"iteration: \" + str(count))\n",
    "    print(\"||AX - b||: \" + str(norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: \n",
      "[2.49915339 3.99851843 4.49830678 3.99851843 2.49915339]\n",
      "iteration: 55\n",
      "||AX - b||: 0.00042330569521809025\n",
      "----------------------------------------------------------------------\n",
      "Solution: \n",
      "[ 4.9982972   8.99673236 11.99543224 13.99450217 14.99401751 14.99401751\n",
      " 13.99450217 11.99543224  8.99673236  4.9982972 ]\n",
      "iteration: 190\n",
      "||AX - b||: 0.0004846660527064728\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in [5,10]:\n",
    "    A = np.diag([-1]*(i-1),1)+np.eye(i)*2+np.diag([-1]*(i-1),-1)\n",
    "    lmethod(A)\n",
    "    print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda equals 2, sounds like the best lambda in this case and the higher we go the later we get the results and the lower we go the norm does not converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
